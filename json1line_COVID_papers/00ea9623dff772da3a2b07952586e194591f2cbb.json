{"paper_id": "00ea9623dff772da3a2b07952586e194591f2cbb", "metadata": {"title": "MUTUAL HYPERLINKING AMONG MISINFORMATION PEDDLERS A PREPRINT", "authors": [{"first": "Vibhor", "middle": [], "last": "Sehgal", "suffix": "", "affiliation": {}, "email": "sehgalvibhor@berkeley.edu"}, {"first": "Ankit", "middle": [], "last": "Peshin", "suffix": "", "affiliation": {}, "email": "ankit.peshin@avast.com"}, {"first": "Sadia", "middle": [], "last": "Afroz", "suffix": "", "affiliation": {}, "email": "sadia.afroz@avast.com"}, {"first": "Hany", "middle": [], "last": "Farid", "suffix": "", "affiliation": {}, "email": "hfarid@berkeley.edu"}]}, "abstract": [{"text": "The internet promised to democratize access to knowledge and make the world more open and understanding. The reality of today's internet, however, is far from this ideal. Misinformation, lies, and conspiracies dominate many social media platforms. This toxic online world has had real-world implications ranging from genocide to, election interference, and threats to global public health. A frustrated public and impatient government regulators are calling for a more vigorous response to mis-and disinformation campaigns designed to sow civil unrest and inspire violence against individuals, societies, and democracies. We describe a large-scale, domain-level analysis that reveals seemingly coordinated efforts between multiple domains to spread and amplify misinformation. We also describe how the hyperlinks shared by certain Twitter users can be used to surface problematic domains. These analyses can be used by search engines and social media recommendation algorithms to systematically discover and demote misinformation peddlers.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}], "body_text": [{"text": "flotsam and jetsam onto our news feeds and watch lists, plunging us into increasingly isolated echo chambers devoid of reality.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "Tackling misinformation at any scale requires striking a balance between public safety and creating an environment that allows for an open exchange of ideas. We don't necessarily advocate a specific solution to achieve this balance, but rather seek to provide the tools to help others find this balance.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "By way of nomenclature, we will refer to a broad category of domains that traffic in conspiracies, distortions, lies, misinformation, and disinformation -whether they are maintained by a state-sponsored actor, a private or public entity, or an individual -as \"misinformational domains.\" All other domains will be referred to as \"informational domains.\" We describe in more detail, in Section 2.1, how domains are characterized as either informational or misinformational.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "Tackling misinformation on a per-post/image/video basis (e.g., [26, 31, 27, 1, 16, 45, 44, 38, 49, 28, 17, 53, 15, 43, 37, 3, 21, 42, 2, 29, 18, 46] ) is leading to a maddeningly massive game of online whack-a-mole. At the same time, social networks are under intense pressure from the public and government regulators to address the scourge of misinformation. We propose that search engines and social media recommendation algorithms would benefit from more aggressively demoting entire domains that are known to traffic in lies, conspiracies, and misinformation. To this end, we describe two techniques for rooting out domains that consistently or primarily traffic in misinformation. This type of domain-level analysis might also be helpful to fact checkers evaluating the reliability of source material.", "cite_spans": [{"start": 63, "end": 67, "text": "[26,", "ref_id": "BIBREF21"}, {"start": 68, "end": 71, "text": "31,", "ref_id": "BIBREF26"}, {"start": 72, "end": 75, "text": "27,", "ref_id": "BIBREF22"}, {"start": 76, "end": 78, "text": "1,", "ref_id": "BIBREF0"}, {"start": 79, "end": 82, "text": "16,", "ref_id": "BIBREF12"}, {"start": 83, "end": 86, "text": "45,", "ref_id": "BIBREF39"}, {"start": 87, "end": 90, "text": "44,", "ref_id": "BIBREF38"}, {"start": 91, "end": 94, "text": "38,", "ref_id": "BIBREF32"}, {"start": 95, "end": 98, "text": "49,", "ref_id": "BIBREF43"}, {"start": 99, "end": 102, "text": "28,", "ref_id": "BIBREF23"}, {"start": 103, "end": 106, "text": "17,", "ref_id": "BIBREF13"}, {"start": 107, "end": 110, "text": "53,", "ref_id": "BIBREF46"}, {"start": 111, "end": 114, "text": "15,", "ref_id": "BIBREF11"}, {"start": 115, "end": 118, "text": "43,", "ref_id": "BIBREF37"}, {"start": 119, "end": 122, "text": "37,", "ref_id": "BIBREF31"}, {"start": 123, "end": 125, "text": "3,", "ref_id": "BIBREF2"}, {"start": 126, "end": 129, "text": "21,", "ref_id": "BIBREF16"}, {"start": 130, "end": 133, "text": "42,", "ref_id": "BIBREF36"}, {"start": 134, "end": 136, "text": "2,", "ref_id": "BIBREF1"}, {"start": 137, "end": 140, "text": "29,", "ref_id": "BIBREF24"}, {"start": 141, "end": 144, "text": "18,", "ref_id": "BIBREF14"}, {"start": 145, "end": 148, "text": "46]", "ref_id": "BIBREF40"}], "ref_spans": [], "section": ""}, {"text": "To better understand the online misinformation ecosystem, we build two networks of misinformational and informational domains: a domain-level hyperlink network and a social-media level link sharing network. The domain-level network represents the hyperlinking relationship between domains. The social-media network represents the link-sharing behavior of social network users. From these networks, we test two main hypotheses: (1) misinformational domains are more connected (through hyperlinks) to each other than to informational domains; and (2) certain social media users are super-spreaders of misinformation. Our primary contributions include:", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "1. Collating and curating a large set of more than 1000 domains identified as trafficking in misinformation.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "2. Revealing a distinct difference between how misinformational and informational domains link to external domains.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "3. Showing how hyperlink differences can predict if a domain traffics in misinformation.", "cite_spans": [], "ref_spans": [], "section": ""}, {"text": "Revealing that certain Twitter users have predictable patterns in their spread of misinformation.", "cite_spans": [], "ref_spans": [], "section": "4."}, {"text": "5. Building a classifier for predicting the likelihood a domain is a misinformation peddler based on how specific Twitter users engage with a domain.", "cite_spans": [], "ref_spans": [], "section": "4."}, {"text": "Over the past five years, academic research on assessing and mitigating misinformation has increased significantly, as has the public's and government's interest in this pressing issue. Research has focused on understanding the nature of misinformation and its impact on the general population [34, 25, 47] , understanding how misinformation spreads [40, 46, 50, 29] , and the automatic detection of misinformation [45, 44, 38, 49, 28, 17, 53, 15, 43, 37, 3, 21, 42, 2, 18, 46, 22] .", "cite_spans": [{"start": 294, "end": 298, "text": "[34,", "ref_id": "BIBREF29"}, {"start": 299, "end": 302, "text": "25,", "ref_id": "BIBREF20"}, {"start": 303, "end": 306, "text": "47]", "ref_id": "BIBREF41"}, {"start": 350, "end": 354, "text": "[40,", "ref_id": "BIBREF34"}, {"start": 355, "end": 358, "text": "46,", "ref_id": "BIBREF40"}, {"start": 359, "end": 362, "text": "50,", "ref_id": "BIBREF44"}, {"start": 363, "end": 366, "text": "29]", "ref_id": "BIBREF24"}, {"start": 415, "end": 419, "text": "[45,", "ref_id": "BIBREF39"}, {"start": 420, "end": 423, "text": "44,", "ref_id": "BIBREF38"}, {"start": 424, "end": 427, "text": "38,", "ref_id": "BIBREF32"}, {"start": 428, "end": 431, "text": "49,", "ref_id": "BIBREF43"}, {"start": 432, "end": 435, "text": "28,", "ref_id": "BIBREF23"}, {"start": 436, "end": 439, "text": "17,", "ref_id": "BIBREF13"}, {"start": 440, "end": 443, "text": "53,", "ref_id": "BIBREF46"}, {"start": 444, "end": 447, "text": "15,", "ref_id": "BIBREF11"}, {"start": 448, "end": 451, "text": "43,", "ref_id": "BIBREF37"}, {"start": 452, "end": 455, "text": "37,", "ref_id": "BIBREF31"}, {"start": 456, "end": 458, "text": "3,", "ref_id": "BIBREF2"}, {"start": 459, "end": 462, "text": "21,", "ref_id": "BIBREF16"}, {"start": 463, "end": 466, "text": "42,", "ref_id": "BIBREF36"}, {"start": 467, "end": 469, "text": "2,", "ref_id": "BIBREF1"}, {"start": 470, "end": 473, "text": "18,", "ref_id": "BIBREF14"}, {"start": 474, "end": 477, "text": "46,", "ref_id": "BIBREF40"}, {"start": 478, "end": 481, "text": "22]", "ref_id": "BIBREF17"}], "ref_spans": [], "section": "Related Work"}, {"text": "With 53% of Americans getting at least some of their news from social media [41] , significant efforts have focused on the promotion and spread of misinformation on social media. Vosoughi et al. [50] , for example, analyzed the spread of misinformation on Twitter and found that false news spreads faster than true news. This study also found false news is more novel than true news and is designed to inspire a strong response of fear, disgust, and surprise, and hence more engagement in terms of likes, share, and retweets. Faddoul et al. [13] and Tang et al. [46] showed how YouTube's own recommendation algorithms help spread conspiracies and misinformation. Automated tools, such as Hoaxy [40] , reveal in real time how misinformation spreads on Twitter.", "cite_spans": [{"start": 76, "end": 80, "text": "[41]", "ref_id": null}, {"start": 195, "end": 199, "text": "[50]", "ref_id": "BIBREF44"}, {"start": 541, "end": 545, "text": "[13]", "ref_id": "BIBREF9"}, {"start": 562, "end": 566, "text": "[46]", "ref_id": "BIBREF40"}, {"start": 694, "end": 698, "text": "[40]", "ref_id": "BIBREF34"}], "ref_spans": [], "section": "Related Work"}, {"text": "The distinctive characteristics of false news stories make it somewhat easier to automatically detect them. A wide range of machine learning approaches have been employed including both traditional classifiers (SVM, LR, Decision Tree, Naive Bayes, k-NN) and machine learning (CNN, LSTM, Bi-LSTM, C-LSTM, HAN, Conv-HAN) models to demonstrate that false news can be automatically detected with a high level of accuracy (see [22] for a comparative study of detection approaches). Having a large and accurately labeled list of misinformational news, however, is difficult to obtain, which is why most studies use small datasets.", "cite_spans": [{"start": 422, "end": 426, "text": "[22]", "ref_id": "BIBREF17"}], "ref_spans": [], "section": "Related Work"}, {"text": "Detection, debunking and fact-checking alone, however, are unlikely to stem the flow of online misinformation. It has been shown, for example, that the effect of misinformation may persist even after false claims have been debunked [9, 24] . We systematically study how over 1000 domains previously identified as peddlers of misinformation, are connected with one another and how this connection can be used to detect and disrupt misinformational networks. This type of hyperlink analysis has previously been examined, however not specifically in the space of misinformation. By analyzing 89 news outlets, for example, Pak et al. [35] found that partisan media outlets are more likely to link to nonpartisan media, but that liberal media link to liberal and neutral outlets, whereas conservative media link more exclusively to conservative outlets. In analyzing hyperlinks between news media between 1999 to 2006, Weber et al. [51] found that establishing hyperlinks with other, younger news outlets strengthens the position of that organization in the network thus boosting traffic.", "cite_spans": [{"start": 232, "end": 235, "text": "[9,", "ref_id": "BIBREF7"}, {"start": 236, "end": 239, "text": "24]", "ref_id": "BIBREF19"}, {"start": 630, "end": 634, "text": "[35]", "ref_id": "BIBREF30"}, {"start": 927, "end": 931, "text": "[51]", "ref_id": "BIBREF45"}], "ref_spans": [], "section": "Related Work"}, {"text": "In contrast to these previous works, by analyzing significantly larger networks (> 1000), we demonstrate more robust patterns of hyperlinking, and specifically focus on the growing problem of misinformation and coordinated misinformation peddlers.", "cite_spans": [], "ref_spans": [], "section": "Related Work"}, {"text": "We begin by collating and curating several public databases of previously identified misinformational and information domains. The domain-level hyperlink network is constructed by scraping all hyperlink tags (<a href=\"...\" </a>) from these domains. These hyperlinks can be to either an internal or external page. A level-1 scraping collects all hyperlinks from the top-level domain; a level-2 scraping collects all hyperlinks by following the level-1 links and repeating the scraping. A graph, G = (V, E) is constructed from the scraped domains. Each vertex/node v \u2208 V corresponds to a domain, and each directed edge e = (A, B) \u2208 E corresponds to a hyperlink from domain A to domain B. As described below, this graph is used to evaluate our underlying hypothesis and to gain further insight in coordinated efforts by seemingly unconnected domains.", "cite_spans": [], "ref_spans": [], "section": "Methods"}, {"text": "The social-media level link sharing network is constructed using the Twitter API to find users who shared links to misinformational domains. We use a user-sharing feature vector as input to linear classifier to predict a domain as being a likely source of misinformation.", "cite_spans": [], "ref_spans": [], "section": "Methods"}, {"text": "We begin by describing the collation and curation of four publicly available misinformation datasets. In total, these four data sets consist of 1,707 domains. There is, however, overlap between these datasets, which once removed yields 1,389 distinct misinformational domains. There are several limitations to immediately using these domains in our analyses. The GossipCop, FakeNewsNet, and PolitiFacts entries, for example, only provide the headline of the offending news article, from which we had to perform a reverse heuristic Google search to identify the source domain. This reverse search does not always identify the offending domain; entertainment stories, for example, often lead to domains like imdb.com and people.com.", "cite_spans": [], "ref_spans": [], "section": "Data Set"}, {"text": "To contend with these limitations, we applied a ranking of the 1,389 domains to down-rank mislabelled domains like imdb.com. Each domain i in our original data set was assigned a score of s i = f i exp(r i /5000), where f i is the frequency with which domain i appeared in our original data set, and r i is the domain's Alexa top-million ranking. The exponential term weights the observation frequency so that highly ranked Alexa domains will have a nearly unit-value weight, and lower rated domains will have a higher weight. The domains with the largest scores s i were then categorized as misinformational. Despite this ranking system, a dozen clearly non-misinformational domains remained in our data set, like theonion.com and huffingtonpost.com. These domains were manually removed, yielding a total of 1,059 domains.", "cite_spans": [], "ref_spans": [], "section": "Data Set"}, {"text": "We paired these 1,059 misinformational domains with 1,059 informational domains corresponding to the top-ranked Alexa domains (which we manually verified are trustworthy domains). We selected 222 domains from the \"news & media\" Alexa categorizaton, 198 domains from each of the \"business\", \"education\", \"entertainment\", and \"sports\" categories, \"45\" from \"health\", and 15 from \"religion.\" Shown in Table 1 are the 20 top-ranked misinformational domains and informational domains and corresponding categories.", "cite_spans": [], "ref_spans": [{"start": 398, "end": 405, "text": "Table 1", "ref_id": null}], "section": "Data Set"}, {"text": "We next used OpenWPM 13 to scrape the hyperlink on each of the 1,059 domains. The hyperlinks tag (<a href=\"...\" </a>) is used to link to an internal or external page. OpenWPM is used to scrape the top-level domain for each hyperlink (level 1), and to scrape all pages linked from this top-level (level 2). This scraping was performed from a Google Cloud Machine with no user login and running Ubuntu 20.04 with 4vCPUs, 16GB RAM and 500GB disk space. Before a hyperlink was scraped the browser was reset and all the cookies were deleted. This entire process was repeated once every two weeks over a six-week period between Feb 19, 2021 and Apr 2, 2021. Any domain that returned a 404 error were excluded from our analysis, yielding a total of 874/1,059 misinformational domains and 888/1,059 informational domains. After scraping all informational and misinformational domains, we constructed an unweighted, directed graph of hyperlinks in which the graph nodes are the domains and a directed edge connects one domain that hyperlinked to another. For example, hoggwatch.com hyperlinks to www.infowars.com/posts/<...> is processed as a directed edge from hoggwatch.com to infowars.com. Shown in Fig. 1 are the level-1 (left) and level-2 (right) graphs in which we can clearly see the strong misinfo-misinfo connections and weak misinfo-info connections.", "cite_spans": [], "ref_spans": [{"start": 1193, "end": 1199, "text": "Fig. 1", "ref_id": "FIGREF0"}], "section": "Domain Scraping"}, {"text": "To visualize and analyze the large hyperlink network, we use the open-source tool Gephi [4] . We use the Louvain method [32, 6] for detecting communities of domains that are connected via hyperlinking relationship. This method is a fast heuristic based on modularity optimization. Networks with high modularity have dense connections between the nodes within modules but sparse connections between nodes in different modules. Since the misinformational domains are more connected to each other than informational domains, we hypothesize the misinformational and informational domains will belong to different communities.", "cite_spans": [{"start": 88, "end": 91, "text": "[4]", "ref_id": "BIBREF3"}, {"start": 120, "end": 124, "text": "[32,", "ref_id": "BIBREF27"}, {"start": 125, "end": 127, "text": "6]", "ref_id": "BIBREF4"}], "ref_spans": [], "section": "Domain Scraping"}, {"text": "3 Results: Domain-Level Hyperlinking", "cite_spans": [], "ref_spans": [], "section": "Domain Scraping"}, {"text": "Each domain in the network created from the misinformational and informational domains are assigned a label of \"misinfo\", \"info\" or \"none\". The \"none\" categorization is used to classify domains not in the misinformational or informational data set. Shown in the top portion of Table 2 is the number and proportion (%) of level-1 hyperlinks from misinfo and info (rows 1-2) to misinfo, none, and info (columns 1-3 ", "cite_spans": [], "ref_spans": [{"start": 277, "end": 284, "text": "Table 2", "ref_id": "TABREF3"}], "section": "Overview"}, {"text": "Shown in the hyperlink graph in Fig. 2 is a small, nearly fully-connected clique of eight domains: cancer.news, climate.news, food.news, health.news, medicine.news, naturalmedicine.news, pollution.news, and sciences.news. This clique is an example of how individual domains can amplify misinformation by, disproportionately, linking to like-minded domains.", "cite_spans": [], "ref_spans": [{"start": 32, "end": 38, "text": "Fig. 2", "ref_id": "FIGREF1"}], "section": "Insights"}, {"text": "Following a reverse whois lookup (www.whois.com), we find all of these misinformational domains are owned by Webseed, LLC based in Arizona, USA. A deeper internet search reveals this LLC was created by Mike Texas, a pseudonym for Mike Adams, founder of Natural News. According to Wikipedia \"Natural News (formerly NewsTarget, which is now a separate sister domain) is an anti-vaccination conspiracy theory and fake news website known for promoting pseudoscience and far-right extremism. Characterized as a \"conspiracy-minded alternative medicine website\", Natural News has approximately 7 million unique visitors per month.\" [52]", "cite_spans": [], "ref_spans": [], "section": "Insights"}, {"text": "The level-2 scraping reveals this clique of eight domains is the tip of the iceberg. Shown in Fig. 3 is a large network of 102 .news domains all owned by Webseed, LLC. In this figure, the red nodes and edges correspond to the original eight-node clique, Fig. 2 . The remaining red nodes are those from our original misinformational data set, and the magenta nodes/edges are misinformational domains discovered by the level-2 scraping. This analysis shows the power of the hyperlinking theory to discover new domains peddling in misinformation.", "cite_spans": [], "ref_spans": [{"start": 94, "end": 100, "text": "Fig. 3", "ref_id": "FIGREF3"}, {"start": 254, "end": 260, "text": "Fig. 2", "ref_id": "FIGREF1"}], "section": "Insights"}, {"text": "Our level-1 scraping also discovered a smaller clique of three domains: blackeyepolitics.com, greatamericandaily.com and americanpatriotdaily.com. Despite forming a fully-connected clique, at first glance these domains appear to be unrelated each with the following ownerships: Rising Media News Network LLC, Great American Daily Press LLC, and American Patriot News LLC, respectively. These domains, however are all owned by David A. Warrington [12] . Warrington also owns other domains including conservativerevival.com and liberalpropagandaexposed.com, the former of which we discovered through our level-2 scraping. This analysis reveals how mutual hyperlinking can reveal seemingly coordinated misinformation efforts despite owners' efforts to conceal their coordination.", "cite_spans": [{"start": 446, "end": 450, "text": "[12]", "ref_id": null}], "ref_spans": [], "section": "Insights"}, {"text": "The above insights were gained by visually inspecting the hyperlink graphs in Fig. 1 . As these graphs increase in size, however, this type of manual approach will quickly become impractical. We, therefore, employ a community detection algorithm [6] to discover connections between a subset of domains.", "cite_spans": [{"start": 246, "end": 249, "text": "[6]", "ref_id": "BIBREF4"}], "ref_spans": [{"start": 78, "end": 84, "text": "Fig. 1", "ref_id": "FIGREF0"}], "section": "Insights"}, {"text": "We applied this community detection algorithm to the level-1 graph in Fig. 1 . This analysis revealed two communities. The first consisted of the following eight domains: globalresearch.ca, journal-neo.org, sott.net, strategic-culture.org, swprs.org, theduran.com, thelibertybeacon.com, and wikispooks.com. The average degree -defined as the sum of all the edges incident to a node -of this community was 3.12 and the graph density was 0.446 (a graph density of 1 signifies a complete graph). Some of these domains have previously been identified as spreading misleading and false COVID-19 related information [14, 5, 19] , three of which appear to be controlled by the Russian intelligence agency [48, 33, 7] .", "cite_spans": [{"start": 610, "end": 614, "text": "[14,", "ref_id": null}, {"start": 615, "end": 617, "text": "5,", "ref_id": null}, {"start": 618, "end": 621, "text": "19]", "ref_id": null}, {"start": 698, "end": 702, "text": "[48,", "ref_id": null}, {"start": 703, "end": 706, "text": "33,", "ref_id": null}, {"start": 707, "end": 709, "text": "7]", "ref_id": null}], "ref_spans": [{"start": 70, "end": 76, "text": "Fig. 1", "ref_id": "FIGREF0"}], "section": "Insights"}, {"text": "The second community consisted of the following five domains: cnsnews.com, protrumpnews.com, thegatewaypundit.com, thepoliticalinsider.com, and waynedupree.com. The average degree of this community was 2.11 and the graph density was 0.12. These domains focus ", "cite_spans": [], "ref_spans": [], "section": "Insights"}, {"text": "Domain cross-linking among misinformational domains adds to the spread of lies and conspiracies. Additionally, billions of world-wide, social-media users are at least equally responsible for spreading misinformation on social media. A recent report, for example, Facebook's own internal research found 111 users are responsible for the majority of anti-vaccination misinformation [11] . We investigate the ability to identify misinformational domains by tracking the hyperlinks shared by certain social-media users. Because of the relative ease of access, we focus on Twitter's publicly available user data. In particular, we enlist two Twitter APIs: (1) The Search Tweets API 14 allows filtering tweets based on a query term against a tweet's keywords, hashtags, or shared URLs. We filter tweets by matching shared URLs against our misinfo/info URL dataset, surfacing which users are sharing a particular domain.; and (2) The Get Tweet Timelines API 15 allows querying all tweets surfaced from the Search Tweets API. In our case, we extract the domain URLs shared by the Twitter users surfaced in the previous step. Although we don't consider them here, the data returned by both APIs contains geo-location, replied-to, time, and other attributes that could be leveraged in the future.", "cite_spans": [{"start": 380, "end": 384, "text": "[11]", "ref_id": "BIBREF8"}], "ref_spans": [], "section": "Results: Link Sharing on Social Media"}, {"text": "Each domain in our misinformational and informational data set is represented by a binary-valued vector corresponding to whether a particular user shared the domain URL. In order to avoid an overly large and sparse representation, starting with a total of 289,984 users from our initial Twitter search, we eliminated 244,525 users who shared less than 2 domains each. The final 45459-D, binary-valued vector serves as the feature vector for each domain.", "cite_spans": [], "ref_spans": [], "section": "Results: Link Sharing on Social Media"}, {"text": "We further remove any domains with fewer than 5 total tweeters, yielding a reduction from 961 to 451 misinformational domains and 962 to 705 informational domains. A total of 1156 domains are split into a 75%/25% training/testing split. In order to balance the training data, random oversampling with replacement is applied to the minority (misinformational) class. We trained a logistic regression (LR) using 75% of the data and then evaluated it on the rest of the 25% data set. The LR hyperparameters are tuned to maximize the F1-score. ", "cite_spans": [], "ref_spans": [], "section": "Results: Link Sharing on Social Media"}, {"text": "From the nature of lies, conspiracies, and rumors, to the methods for their delivery and spread, misinformation has, and is likely to continue to be an ever-evolving phenomena. While misinformation is not new, the consequences of its collision with a vast digital landscape has led to significant offline harms to individuals, marginalized groups, societies, and our very democracies. Addressing these harms will require a multi-faceted approach from thoughtful government regulation, to corporate responsibility, technological advances, and education.", "cite_spans": [], "ref_spans": [], "section": "Discussion"}, {"text": "As with most aspects of cybersecurity, technological solutions to addressing misinformation will themselves have to be multi-faceted. With some 500 hours of video uploaded to YouTube every minute, and over a billion posts to Facebook each day, the massive scale of social media makes tackling misinformation an enormous challenge. We propose that in conjunction with complementary approaches to tackling misinformation, addressing misinformation at the domain level holds promise to disrupt large-scale misinformation campaigns. Previous studies have found a relatively small group of individuals are responsible for a disproportionate number of lies and conspiracies. Identifying this group, and reducing their reach -while not necessarily silencing them entirely -holds the potential to make a large dent in the online proliferation of harmful misinformation.", "cite_spans": [], "ref_spans": [], "section": "Discussion"}, {"text": "We understand and appreciate the need to balance an open and free internet, where ideas can be debated, with the need to protect individuals, societies, and democracies. Social media, however, cannot hide behind the facade they are creating a neutral marketplace of ideas where good and bad ideas compete equally. They do not. It is well established that social media's recommendation algorithms favor the outrageous and conspiratorial because it increases engagement and profit. As a result, Brandies' concept that the best remedy for falsehoods is more speech, not less, simply doesn't apply in the era of algorithmic curation and amplification. We propose that identified misinformation peddlers not necessarily be banned or de-platformed, but that their content simply be demoted in favor of more honest, civil, and trustworthy content.", "cite_spans": [], "ref_spans": [], "section": "Discussion"}, {"text": "As with any inherently adversarial relationship, all approaches to addressing misinformation -including ours -will have to adapt to new and emerging threats. In our case, misinformation peddlers may add decoy hyperlinks to external trustworthy domains to escape being classified based on their hyperlinks to other misinformational domains. This, in turn, will require techniques to root out such decoy links. And so on, and on, and on. While such a cat and mouse game can be frustrating, the end game will be that it will become increasingly more difficult and time consuming to create and spread misinformation, with the eventual goal of discouraging most, leaving us to contend with the die-hard adversary. While this is not a complete success, it will mitigate the risk of misinformation and, hopefully, return some civility and trust to our online ecosystems.", "cite_spans": [], "ref_spans": [], "section": "Discussion"}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Protecting world leaders against deep fakes", "authors": [{"first": "S", "middle": [], "last": "Agarwal", "suffix": ""}, {"first": "H", "middle": [], "last": "Farid", "suffix": ""}, {"first": "Y", "middle": [], "last": "Gu", "suffix": ""}, {"first": "M", "middle": [], "last": "He", "suffix": ""}, {"first": "K", "middle": [], "last": "Nagano", "suffix": ""}, {"first": "H", "middle": [], "last": "Li", "suffix": ""}], "year": 2019, "venue": "IEEE Conference on Computer Vision and Pattern Recognition Workshops", "volume": "", "issn": "", "pages": "38--45", "other_ids": {}}, "BIBREF1": {"ref_id": "b1", "title": "Detecting fake news in social media networks", "authors": [{"first": "M", "middle": [], "last": "Aldwairi", "suffix": ""}, {"first": "A", "middle": [], "last": "Alwahedi", "suffix": ""}], "year": 2018, "venue": "Procedia Computer Science", "volume": "141", "issn": "", "pages": "215--222", "other_ids": {}}, "BIBREF2": {"ref_id": "b2", "title": "Detecting fake news with machine learning method", "authors": [{"first": "S", "middle": [], "last": "Aphiwongsophon", "suffix": ""}, {"first": "P", "middle": [], "last": "Chongstitvatana", "suffix": ""}], "year": 2018, "venue": "15th International Conference on Electrical Engineering/Electronics", "volume": "", "issn": "", "pages": "528--531", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Gephi: an open source software for exploring and manipulating networks", "authors": [{"first": "M", "middle": [], "last": "Bastian", "suffix": ""}, {"first": "S", "middle": [], "last": "Heymann", "suffix": ""}, {"first": "M", "middle": [], "last": "Jacomy", "suffix": ""}], "year": 2009, "venue": "Proceedings of the International AAAI Conference on Web and Social Media", "volume": "3", "issn": "", "pages": "", "other_ids": {}}, "BIBREF4": {"ref_id": "b4", "title": "Fast unfolding of communities in large networks", "authors": [{"first": "V", "middle": ["D"], "last": "Blondel", "suffix": ""}, {"first": "J.-L", "middle": [], "last": "Guillaume", "suffix": ""}, {"first": "R", "middle": [], "last": "Lambiotte", "suffix": ""}, {"first": "E", "middle": [], "last": "Lefebvre", "suffix": ""}], "year": 2008, "venue": "Journal of Statistical Mechanics: Theory and Experiment", "volume": "10", "issn": "", "pages": "", "other_ids": {}}, "BIBREF6": {"ref_id": "b6", "title": "Addressing Far-Right QAnon Conspiracy, Offers Praise For Its Followers", "authors": [{"first": "B", "middle": [], "last": "Cater", "suffix": ""}, {"first": "", "middle": [], "last": "Trump", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "Debunking: A meta-analysis of the psychological efficacy of messages countering misinformation", "authors": [{"first": "M.-P", "middle": ["S"], "last": "Chan", "suffix": ""}, {"first": "C", "middle": ["R"], "last": "Jones", "suffix": ""}, {"first": "", "middle": [], "last": "Hall", "suffix": ""}, {"first": "K", "middle": [], "last": "Jamieson", "suffix": ""}, {"first": "D", "middle": [], "last": "Albarrac\u00edn", "suffix": ""}], "year": 2017, "venue": "Psychological Science", "volume": "28", "issn": "", "pages": "1531--1546", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Massive facebook study on users' doubt in vaccines finds a small group appears to play a big role in pushing the skepticism", "authors": [{"first": "E", "middle": [], "last": "Dwoskin", "suffix": ""}], "year": 2021, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF9": {"ref_id": "b9", "title": "A Longitudinal Analysis of YouTube's Promotion of Conspiracy Videos", "authors": [{"first": "M", "middle": [], "last": "Faddoul", "suffix": ""}, {"first": "G", "middle": [], "last": "Chaslot", "suffix": ""}, {"first": "H", "middle": [], "last": "Farid", "suffix": ""}], "year": 2003, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF11": {"ref_id": "b11", "title": "Deep learning algorithms for detecting fake news in online text", "authors": [{"first": "S", "middle": [], "last": "Girgis", "suffix": ""}, {"first": "E", "middle": [], "last": "Amer", "suffix": ""}, {"first": "M", "middle": [], "last": "Gadallah", "suffix": ""}], "year": 2018, "venue": "13th International Conference on Computer Engineering and Systems", "volume": "", "issn": "", "pages": "93--97", "other_ids": {}}, "BIBREF12": {"ref_id": "b12", "title": "Deepfake video detection using recurrent neural networks", "authors": [{"first": "D", "middle": [], "last": "G\u00fcera", "suffix": ""}, {"first": "E", "middle": ["J"], "last": "Delp", "suffix": ""}], "year": 2018, "venue": "15th IEEE International Conference on Advanced Video and Signal Based Surveillance", "volume": "", "issn": "", "pages": "1--6", "other_ids": {}}, "BIBREF13": {"ref_id": "b13", "title": "A retrospective analysis of the fake news challenge stance detection task", "authors": [{"first": "A", "middle": [], "last": "Hanselowski", "suffix": ""}, {"first": "A", "middle": [], "last": "Pvs", "suffix": ""}, {"first": "B", "middle": [], "last": "Schiller", "suffix": ""}, {"first": "F", "middle": [], "last": "Caspelherr", "suffix": ""}, {"first": "D", "middle": [], "last": "Chaudhuri", "suffix": ""}, {"first": "C", "middle": ["M"], "last": "Meyer", "suffix": ""}, {"first": "I", "middle": [], "last": "Gurevych", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1806.05180"]}}, "BIBREF14": {"ref_id": "b14", "title": "Identifying disinformation websites using infrastructure features", "authors": [{"first": "A", "middle": [], "last": "Hounsel", "suffix": ""}, {"first": "J", "middle": [], "last": "Holland", "suffix": ""}, {"first": "B", "middle": [], "last": "Kaiser", "suffix": ""}, {"first": "K", "middle": [], "last": "Borgolte", "suffix": ""}, {"first": "N", "middle": [], "last": "Feamster", "suffix": ""}, {"first": "J", "middle": [], "last": "Mayer", "suffix": ""}], "year": 2020, "venue": "10th USENIX Workshop on Free and Open Communications on the Internet", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF15": {"ref_id": "b15", "title": "More than 1 in 3 Americans believe a 'deep state' is working to undermine Trump", "authors": [], "year": 2020, "venue": "IPSOS", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF16": {"ref_id": "b16", "title": "Multi-source multi-class fake news detection", "authors": [{"first": "H", "middle": [], "last": "Karimi", "suffix": ""}, {"first": "P", "middle": [], "last": "Roy", "suffix": ""}, {"first": "S", "middle": [], "last": "Saba-Sadiya", "suffix": ""}, {"first": "J", "middle": [], "last": "Tang", "suffix": ""}], "year": 2018, "venue": "27th International Conference on Computational Linguistics", "volume": "", "issn": "", "pages": "1546--1557", "other_ids": {}}, "BIBREF17": {"ref_id": "b17", "title": "A benchmark study of machine learning models for online fake news detection", "authors": [{"first": "J", "middle": ["Y"], "last": "Khan", "suffix": ""}, {"first": "M", "middle": ["T I"], "last": "Khondaker", "suffix": ""}, {"first": "S", "middle": [], "last": "Afroz", "suffix": ""}, {"first": "G", "middle": [], "last": "Uddin", "suffix": ""}, {"first": "A", "middle": [], "last": "Iqbal", "suffix": ""}], "year": 2021, "venue": "Machine Learning with Applications", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF18": {"ref_id": "b18", "title": "LEADSTORIES", "authors": [], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF19": {"ref_id": "b19", "title": "Beyond misinformation: Understanding and coping with the \"post-truth\" era", "authors": [{"first": "S", "middle": [], "last": "Lewandowsky", "suffix": ""}, {"first": "U", "middle": ["K"], "last": "Ecker", "suffix": ""}, {"first": "J", "middle": [], "last": "Cook", "suffix": ""}], "year": 2017, "venue": "Journal of Applied Research in Memory and Cognition", "volume": "6", "issn": "", "pages": "353--369", "other_ids": {}}, "BIBREF20": {"ref_id": "b20", "title": "Misinformation and its correction: Continued influence and successful debiasing", "authors": [{"first": "S", "middle": [], "last": "Lewandowsky", "suffix": ""}, {"first": "U", "middle": ["K"], "last": "Ecker", "suffix": ""}, {"first": "C", "middle": ["M"], "last": "Seifert", "suffix": ""}, {"first": "N", "middle": [], "last": "Schwarz", "suffix": ""}, {"first": "J", "middle": [], "last": "Cook", "suffix": ""}], "year": 2012, "venue": "Psychological Science in the Public Interest", "volume": "13", "issn": "", "pages": "106--131", "other_ids": {}}, "BIBREF21": {"ref_id": "b21", "title": "Exposing deepfake videos by detecting face warping artifacts", "authors": [{"first": "Y", "middle": [], "last": "Li", "suffix": ""}, {"first": "S", "middle": [], "last": "Lyu", "suffix": ""}], "year": 2018, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1811.00656"]}}, "BIBREF22": {"ref_id": "b22", "title": "Celeb-df: A large-scale challenging dataset for deepfake forensics", "authors": [{"first": "Y", "middle": [], "last": "Li", "suffix": ""}, {"first": "X", "middle": [], "last": "Yang", "suffix": ""}, {"first": "P", "middle": [], "last": "Sun", "suffix": ""}, {"first": "H", "middle": [], "last": "Qi", "suffix": ""}, {"first": "S", "middle": [], "last": "Lyu", "suffix": ""}], "year": 2020, "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition", "volume": "", "issn": "", "pages": "3207--3216", "other_ids": {}}, "BIBREF23": {"ref_id": "b23", "title": "Early detection of fake news on social media through propagation path classification with recurrent and convolutional networks", "authors": [{"first": "Y", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Y.-F", "middle": [], "last": "Wu", "suffix": ""}], "year": 2018, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "volume": "32", "issn": "", "pages": "", "other_ids": {}}, "BIBREF24": {"ref_id": "b24", "title": "Detect rumors in microblog posts using propagation structure via kernel learning", "authors": [{"first": "J", "middle": [], "last": "Ma", "suffix": ""}, {"first": "W", "middle": [], "last": "Gao", "suffix": ""}, {"first": "K.-F", "middle": [], "last": "Wong", "suffix": ""}], "year": 2017, "venue": "55th Annual Meeting of the Association for Computational Linguistics", "volume": "", "issn": "", "pages": "708--717", "other_ids": {}}, "BIBREF25": {"ref_id": "b25", "title": "The hockey stick and the climate wars: Dispatches from the front lines", "authors": [{"first": "M", "middle": ["E"], "last": "Mann", "suffix": ""}], "year": 2013, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF26": {"ref_id": "b26", "title": "Exploiting visual artifacts to expose deepfakes and face manipulations", "authors": [{"first": "F", "middle": [], "last": "Matern", "suffix": ""}, {"first": "C", "middle": [], "last": "Riess", "suffix": ""}, {"first": "M", "middle": [], "last": "Stamminger", "suffix": ""}], "year": 2019, "venue": "IEEE Winter Applications of Computer Vision Workshops", "volume": "", "issn": "", "pages": "83--92", "other_ids": {}}, "BIBREF27": {"ref_id": "b27", "title": "Modularity and community structure in networks", "authors": [{"first": "M", "middle": ["E"], "last": "Newman", "suffix": ""}], "year": 2006, "venue": "Proceedings of the National Academy of Sciences", "volume": "103", "issn": "23", "pages": "8577--8582", "other_ids": {}}, "BIBREF29": {"ref_id": "b29", "title": "Examining the Global Spread of COVID-19 Misinformation", "authors": [{"first": "S", "middle": [], "last": "Nightingale", "suffix": ""}, {"first": "H", "middle": [], "last": "Farid", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2006.08830"]}}, "BIBREF30": {"ref_id": "b30", "title": "Intermedia reliance and sustainability of emergent media: A large-scale analysis of american news outlets' external linking behaviors", "authors": [{"first": "C", "middle": [], "last": "Pak", "suffix": ""}, {"first": "K", "middle": [], "last": "Cotter", "suffix": ""}, {"first": "J", "middle": [], "last": "Decook", "suffix": ""}], "year": 2020, "venue": "International Journal of Communication", "volume": "14", "issn": "", "pages": "", "other_ids": {}}, "BIBREF31": {"ref_id": "b31", "title": "Supervised learning for fake news detection", "authors": [{"first": "J", "middle": ["C"], "last": "Reis", "suffix": ""}, {"first": "A", "middle": [], "last": "Correia", "suffix": ""}, {"first": "F", "middle": [], "last": "Murai", "suffix": ""}, {"first": "A", "middle": [], "last": "Veloso", "suffix": ""}, {"first": "F", "middle": [], "last": "Benevenuto", "suffix": ""}], "year": 2019, "venue": "IEEE Intelligent Systems", "volume": "34", "issn": "", "pages": "76--81", "other_ids": {}}, "BIBREF32": {"ref_id": "b32", "title": "CSI: A hybrid deep model for fake news detection", "authors": [{"first": "N", "middle": [], "last": "Ruchansky", "suffix": ""}, {"first": "S", "middle": [], "last": "Seo", "suffix": ""}, {"first": "Y", "middle": [], "last": "Liu", "suffix": ""}], "year": 2017, "venue": "ACM on Conference on Information and Knowledge Management", "volume": "", "issn": "", "pages": "797--806", "other_ids": {}}, "BIBREF33": {"ref_id": "b33", "title": "The difference between what Republicans and Democrats believe to be true about COVID-19", "authors": [{"first": "L", "middle": [], "last": "Sanders", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF34": {"ref_id": "b34", "title": "Anatomy of an online misinformation network", "authors": [{"first": "C", "middle": [], "last": "Shao", "suffix": ""}, {"first": "P.-M", "middle": [], "last": "Hui", "suffix": ""}, {"first": "L", "middle": [], "last": "Wang", "suffix": ""}, {"first": "X", "middle": [], "last": "Jiang", "suffix": ""}, {"first": "A", "middle": [], "last": "Flammini", "suffix": ""}, {"first": "F", "middle": [], "last": "Menczer", "suffix": ""}, {"first": "G", "middle": ["L"], "last": "Ciampaglia", "suffix": ""}], "year": 2018, "venue": "PloS one", "volume": "13", "issn": "", "pages": "", "other_ids": {}}, "BIBREF36": {"ref_id": "b36", "title": "Detecting fake news on social media", "authors": [{"first": "K", "middle": [], "last": "Shu", "suffix": ""}, {"first": "H", "middle": [], "last": "Liu", "suffix": ""}], "year": 2019, "venue": "Synthesis Lectures on Data Mining and Knowledge discovery", "volume": "11", "issn": "", "pages": "1--129", "other_ids": {}}, "BIBREF37": {"ref_id": "b37", "title": "Understanding user profiles on social media for fake news detection", "authors": [{"first": "K", "middle": [], "last": "Shu", "suffix": ""}, {"first": "S", "middle": [], "last": "Wang", "suffix": ""}, {"first": "H", "middle": [], "last": "Liu", "suffix": ""}], "year": 2018, "venue": "IEEE Conference on Multimedia Information Processing and Retrieval", "volume": "", "issn": "", "pages": "430--435", "other_ids": {}}, "BIBREF38": {"ref_id": "b38", "title": "Beyond news contents: The role of social context for fake news detection", "authors": [{"first": "K", "middle": [], "last": "Shu", "suffix": ""}, {"first": "S", "middle": [], "last": "Wang", "suffix": ""}, {"first": "H", "middle": [], "last": "Liu", "suffix": ""}], "year": 2019, "venue": "12th ACM International Conference on Web Search and Data Mining", "volume": "", "issn": "", "pages": "312--320", "other_ids": {}}, "BIBREF39": {"ref_id": "b39", "title": "The role of user profiles for fake news detection", "authors": [{"first": "K", "middle": [], "last": "Shu", "suffix": ""}, {"first": "X", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "S", "middle": [], "last": "Wang", "suffix": ""}, {"first": "R", "middle": [], "last": "Zafarani", "suffix": ""}, {"first": "H", "middle": [], "last": "Liu", "suffix": ""}], "year": 2019, "venue": "IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining", "volume": "", "issn": "", "pages": "436--439", "other_ids": {}}, "BIBREF40": {"ref_id": "b40", "title": "down the rabbit hole\" of vaccine misinformation on youtube: Network exposure study", "authors": [{"first": "L", "middle": [], "last": "Tang", "suffix": ""}, {"first": "K", "middle": [], "last": "Fujimoto", "suffix": ""}, {"first": "M", "middle": ["T"], "last": "Amith", "suffix": ""}, {"first": "R", "middle": [], "last": "Cunningham", "suffix": ""}, {"first": "R", "middle": ["A"], "last": "Costantini", "suffix": ""}, {"first": "F", "middle": [], "last": "York", "suffix": ""}, {"first": "G", "middle": [], "last": "Xiong", "suffix": ""}, {"first": "J", "middle": ["A"], "last": "Boom", "suffix": ""}, {"first": "C", "middle": [], "last": "Tao", "suffix": ""}], "year": 2021, "venue": "Journal of Medical Internet Research", "volume": "23", "issn": "", "pages": "", "other_ids": {}}, "BIBREF41": {"ref_id": "b41", "title": "Belief echoes: The persistent effects of corrected misinformation", "authors": [{"first": "E", "middle": [], "last": "Thorson", "suffix": ""}], "year": 2016, "venue": "Political Communication", "volume": "33", "issn": "", "pages": "460--480", "other_ids": {}}, "BIBREF43": {"ref_id": "b43", "title": "Fake news detection in social networks via crowd signals", "authors": [{"first": "S", "middle": [], "last": "Tschiatschek", "suffix": ""}, {"first": "A", "middle": [], "last": "Singla", "suffix": ""}, {"first": "M", "middle": [], "last": "Gomez Rodriguez", "suffix": ""}, {"first": "A", "middle": [], "last": "Merchant", "suffix": ""}, {"first": "A", "middle": [], "last": "Krause", "suffix": ""}], "year": 2018, "venue": "Companion Proceedings of the The Web Conference", "volume": "", "issn": "", "pages": "517--524", "other_ids": {}}, "BIBREF44": {"ref_id": "b44", "title": "The spread of true and false news online", "authors": [{"first": "S", "middle": [], "last": "Vosoughi", "suffix": ""}, {"first": "D", "middle": [], "last": "Roy", "suffix": ""}, {"first": "S", "middle": [], "last": "Aral", "suffix": ""}], "year": 2018, "venue": "Science", "volume": "359", "issn": "", "pages": "1146--1151", "other_ids": {}}, "BIBREF45": {"ref_id": "b45", "title": "Newspapers and the long-term implications of hyperlinking", "authors": [{"first": "M", "middle": ["S"], "last": "Weber", "suffix": ""}], "year": 2012, "venue": "Journal of Computer-Mediated Communication", "volume": "17", "issn": "", "pages": "187--201", "other_ids": {}}, "BIBREF46": {"ref_id": "b46", "title": "Detecting fake news for reducing misinformation risks using analytics approaches", "authors": [{"first": "C", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "A", "middle": [], "last": "Gupta", "suffix": ""}, {"first": "C", "middle": [], "last": "Kauten", "suffix": ""}, {"first": "A", "middle": ["V"], "last": "Deokar", "suffix": ""}, {"first": "X", "middle": [], "last": "Qin", "suffix": ""}], "year": 2019, "venue": "European Journal of Operational Research", "volume": "279", "issn": "", "pages": "1036--1052", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "Hyperlink connectivity between misinformational (red) and informational domains for level-1 (left) and level-2 (right) scraping.. Each node corresponds to a domain and a directed edge between domain i and domain j signifies a hyperlink on domain i to domain j. The nodes colored red correspond to misinformational domains, and the remaining nodes correspond to different categories of information domains.", "latex": null, "type": "figure"}, "FIGREF1": {"text": "A magnified view of eight almost fully connected .news domains, all owned by Webseed.", "latex": null, "type": "figure"}, "FIGREF2": {"text": "primarily on pro-Trump misinformation. The site thegatewaypundit.com, led by Jim Hoft, for example, promoted false rumors about voter fraud and Hillary Clinton's health in the 2016 US-national election. Earlier this year, Hoft was banned from Twitter for \"repeated violations of Twitter's civic integrity policy.\" Similarly, cnsnews.com is run by the daughter of Republican mega-donor, Robert Mercer. Mercer has been implicated in the weaponization of millions of misinformation-spreading Twitter bots [10]. These types of communities are quite common. Our analysis revealed misinformational domains dominate the five largest communities: (1) the largest community consisted of 79 domains, 88.6% of which are misinformational; followed by (2) 75 domains, 46.7% of which are misinformational; (3) 50 domains, 38% of which are misinformational; (4) 46 domains, 87.0% of which are misinformational; and lastly (5) 39 domains, 82.1% of which are misinformational.", "latex": null, "type": "figure"}, "FIGREF3": {"text": "Level-2 scraping of hyperlinks reveals a network of 102 .news domains. The red nodes and edges correspond to the original eight-node clique,Fig. 2. The remaining red nodes are those from our original misinformational data set, and the magenta nodes/edges are misinformational domains discovered by the second-level scraping.", "latex": null, "type": "figure"}, "FIGREF4": {"text": "Mutual domain URL sharing by Twitter users, where each node is a domain. Undirected edges connect two domains A and B if at least 1% of the users sharing either A or B also shared the other domain (i.e., the Jaccard index is greater than 1%). Nodes with no connections have been dropped.", "latex": null, "type": "figure"}, "TABREF1": {"text": "\u2022 BS Detector 1 : This data set is based on the \"BS detector\" browser extension2 . This extension uses a manually curated list of misinformational domains to label linked articles as reliable or not. This data set consists of 244 unique domains. \u2022 Columbia Journalism Review 3 : This dataset consists of manually curated misinformational stories scraped from Factcheck 4 , Fake News Codex 5 , OpenSources 6 , PolitiFact 7 and Snopes 8 . This data set consists of 155 unique domains. \u2022 FakeNewsNet 9 : This data set consists of manually curated misinformational stories scraped from PolitiFact 10 and GossipCop 11 . While PolitiFact is primarily focused on political news, GossipCop is primarily focused on the entertainment industry. This data set consists of 898 unique domains. \u2022 Media Bias Fact Check 12 : This data set consists of a manually curated and continually updated list of news", "latex": null, "type": "table"}, "TABREF3": {"text": "Level 1 (top)  and level 2 (bottom) hyperlink network analysis. Each entry corresponds to the number and percentage of total links from one domain (row) to another (column). The label \"none\" corresponds to domains that are not labeled as misinformational (misinfo) or informational (info). In level 1 analysis, 17.90% of hyperlinks on misinfo domains are to other misinfo domains, as compared to only 0.62% of hyperlinks on info domains. This pattern persists in level 2, albeit with a smaller difference, 9.27% versus 1.03%.Included in the 60 info to misinfo hyperlinks we discovered, is the news & media site drudgereport.com hyperlinking to sites like breitbart.com and thegatewaypundit.com, each of whom have been implicated in spreading misinformation and conspiracies[36,23]. Other examples include the entertainment site indiewire.com linking to hollywoodlife.com, notorious for spreading gossip and misinformation.", "latex": null, "type": "table"}, "TABREF4": {"text": "Domains such as dailywire.com, fortherightnews.com, newsblaze.com, nickiswift.com, therightscoop.com, trueactivist.com, and usasupreme.com, were correctly classified as misinformational. The classifier incorrectly inferred the following domains as informational, indicating they are shared along with other informational domains: cancer.news, celebrityinsider.org, hollywoodreporter.com, medicine.news, medicalmedium.com, science.news, and trump.news.To visualize the informational and misinformational domains shared by Twitter users, we construct an undirected graph G = (V, E) where each node v \u2208 V represents a domain, and two vertices A, B \u2208 V are connected by an undirected edge, e = (A, B) \u2208 E, if at least 1% of the users sharing either domain A or B share both of them (i.e., Jaccard Similarity \u2265 1%). In this visualization,Fig. 4-and consistent with our findings from the previous section -we see strong misinfo-misinfo connectivity and weak misinfo-info connectivity. In particular, misinfo/info domains have an average of 7.55/1.57 connections, respectively, within their category, and 1.00/0.86 connections outside their category.A community analysis reveals some large communities dominated by misinformation domains: (1) the largest such community consists of 131 domains, 89.3% of which are misinformational; followed by (2) 58 domains, 86.2% of which are misinformational; and (3) 46 domains, 91.3% of which are misinformational. We found a particularly interesting community of 14 domains dominated by climate-change deniers, which includes domains like: cfact.org, climatism.blog, climatechangedispatch.com, iceagenow.info, iowaclimate.org, notrickszone.com, realclimatescience.com, and wattsupwiththat.com. A total of 13 of the 14 domains in this community are misinformational domains, and one in particular, wattsupwiththat.com, has been identified by climatologist Michael E. Mann as \"the leading climate change denial blog\"[30].", "latex": null, "type": "table"}}, "back_matter": [{"text": "This work was supported by funding from funding Avast, Inc. (Sehgal and Farid). We thank Juyong Do and Rajarshi Gupta for their thoughtful comments and discussions.", "cite_spans": [], "ref_spans": [], "section": "Acknowledgments"}]}